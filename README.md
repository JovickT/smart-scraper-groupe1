# ğŸš„ Smart Scraper - Groupe 1

Ce projet est une application web qui **scrape les donnÃ©es de frÃ©quentation des gares SNCF** et les affiche sur une interface web. Il utilise un backend Flask connectÃ© Ã  une base de donnÃ©es MySQL, et un frontend en React.

---

## ğŸ“¦ Technologies utilisÃ©es

* **Backend** : Flask + SQLAlchemy
* **Frontend** : React
* **Base de donnÃ©es** : MySQL 8
* **Scraping** : API publique de la SNCF
* **Conteneurisation** : Docker & Docker Compose

---

## ğŸš€ Installation & Lancement

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/JovickT/smart-scraper-groupe1.git
cd smart-scraper-groupe1
```

### 2. CrÃ©er un environnement virtuel pour le backend (optionnel pour dev local)

```bash
cd backend
python -m venv venv
```

> Active lâ€™environnement selon ton OS si tu veux travailler hors Docker.

### 3. Revenir Ã  la racine et dÃ©marrer les conteneurs

```bash
cd ..
docker compose up -d
```

> Cela lance :
>
> * le backend Flask (port `5000`)
> * le frontend React (port `3000`)
> * la base MySQL (port `3306`)

---

## ğŸ“¡ Utilisation

### 1. Lancer le scraping via Postman (ou curl)

AprÃ¨s avoir dÃ©marrÃ© les conteneurs avec `docker compose up -d`, **attends quelques secondes** que la base de donnÃ©es et le backend soient bien prÃªts.

Ensuite, effectue une requÃªte **POST** :

```
POST http://localhost:5000/api/scrape
```

ğŸ“Œ **Important** :
Il se peut que la base de donnÃ©es prenne un petit moment Ã  Ãªtre prÃªte. Si la requÃªte Ã©choue au dÃ©but, rÃ©essaie jusqu'Ã  ce que tu obtiennes dans la rÃ©ponse :

```json
{
  "message": "Scraping terminÃ© avec succÃ¨s."
}
```

ğŸ‘‰ Cela signifie que les donnÃ©es ont bien Ã©tÃ© insÃ©rÃ©es dans la base MySQL.

---

### 2. AccÃ©der Ã  l'application

Ouvre ton navigateur :

```
http://localhost:3000/
```

Tu verras lâ€™interface React avec les donnÃ©es affichÃ©es.

---

## ğŸ“ Structure du projet

```
smart-scraper-groupe1/
â”‚
â”œâ”€â”€ backend/          # Code Flask
â”œâ”€â”€ frontend/         # Code React
â”œâ”€â”€ database/         # init.sql pour la BDD
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## âœ… Ã€ venir

* Filtrage avancÃ© des donnÃ©es (dates, rÃ©gionsâ€¦)
* Export CSV
* Authentification

---

## ğŸ§‘â€ğŸ’» Auteurs

Projet rÃ©alisÃ© par le **Groupe 1** â€” Mastere EEDSI

EncadrÃ© dans le cadre du cours de scraping web.



